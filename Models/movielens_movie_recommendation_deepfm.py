# -*- coding: utf-8 -*-
"""MovieLens Movie Recommendation-DeepFM.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/190NewfDy9qOvWjfcn7sBh5jsT28Fbngk
"""

!pip install deepctr_torch

import pandas as pd
from sklearn.metrics import mean_squared_error
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
import os
import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
import random
import gc

import torch
from deepctr_torch.inputs import SparseFeat, VarLenSparseFeat, get_feature_names
from deepctr_torch.models import DeepFM
from sklearn.preprocessing import LabelEncoder

data = pd.read_csv("/content/movielens_sample.txt")
sparse_features = ["movie_id", "user_id", "gender", "age", "occupation", "zip"]
target = ['rating']

for feature in sparse_features:
    lbe = LabelEncoder()
    data[feature] = lbe.fit_transform(data[feature])

fixlen_feature_columns = [SparseFeat(feature, data[feature].nunique()) for feature in sparse_features]
print(fixlen_feature_columns)
linear_feature_columns = fixlen_feature_columns
dnn_feature_columns = fixlen_feature_columns
feature_names = get_feature_names(linear_feature_columns + dnn_feature_columns)

class MovieLensDataset(Dataset):

    def __init__(self, users, movies, ratings):
        self.users = users
        self.movies = movies
        self.ratings = ratings

    def __len__(self):
        return len(self.users)

    def __getitem__(self,idx):
        user = self.users[idx]
        movie = self.movies[idx]
        rating = self.ratings[idx]

        return {
               "users" : torch.tensor(user),
               "movies" : torch.tensor(movie),
               "ratings" : torch.tensor(rating)
                }

train, test = train_test_split(data, test_size=0.2)
train_model_input = {name:train[name].values for name in feature_names}
test_model_input = {name:test[name].values for name in feature_names}

train_data, test_data = train_test_split(df, test_size=0.2, random_state=42, stratify=df.like.values)
test_data, val_data = train_test_split(test_data, test_size=0.5, random_state=42, stratify=test_data.like.values)

train_dataset = MovieLensDataset(train_data.user_id.values, train_data.movie_id.values, train_data.like.values)
val_dataset = MovieLensDataset(val_data.user_id.values, val_data.movie_id.values, val_data.like.values)
test_dataset = MovieLensDataset(test_data.user_id.values, test_data.movie_id.values, test_data.like.values)

train_dl = DataLoader(train_dataset, batch_size=1024,shuffle=True)
val_dl = DataLoader(val_dataset, batch_size=1024,shuffle=True)
test_dl = DataLoader(test_dataset, batch_size=1024,shuffle=True)

model = DeepFM(linear_feature_columns, dnn_feature_columns, task='regression')
model.compile("adam", "mse", metrics=['mse'], )
history = model.fit(train_model_input, train[target].values,
                    batch_size=256, epochs=100, verbose=True, validation_split=0.2,
                    validation_data=(test_model_input, test[target].values))

pred_ans = model.predict(test_model_input, batch_size=256)

mse = round(mean_squared_error(test[target].values, pred_ans), 4)
rmse = mse ** 0.5
print("test RMSE", rmse)

plt.plot(history.history['loss'], label='train')
plt.legend()
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.title('Training and Validation Loss Curves')
plt.show()

import pandas as pd
import numpy as np
import random
import matplotlib.pyplot as plt
import torch
import torch.nn.functional as F
import torch.nn as nn
from torch.utils.data import Dataset, DataLoader
from sklearn import preprocessing
from sklearn.model_selection import train_test_split
from sklearn.metrics import precision_score,recall_score,accuracy_score,roc_curve,auc

movies_df = pd.read_table("/content/movies.dat",sep="::",names=['id','title','genres'],encoding='latin-1')
ratings_df = pd.read_table("/content/ratings.dat",sep="::",names=['user_id','movie_id','rating','timestamp'])

ratings_df = pd.merge(ratings_df, movies_df, how='left', left_on='movie_id', right_on='id')
ratings_df.head()

ratings_df.describe()

ratings_df.rating.plot.hist(bins=5)

movie_stats = ratings_df.groupby("movie_id",as_index=False).aggregate(
    {'user_id' : 'count', 'rating' : 'mean'}).rename(columns={'user_id' : '#watch', 'rating' : 'avg_rating'})

movie_stats = pd.merge(movie_stats,movies_df,how='left',left_on='movie_id',right_on='id')[['title','#watch','avg_rating']]
movie_stats.head()

# top 10 most popular movies
ax = movie_stats.sort_values(by=['#watch'],ascending=False)[:10].plot(x='title',y='#watch',kind='bar',figsize=(12,6),legend=False,ylabel='#watch')
ax.bar_label(ax.containers[0])

# top 10 most liked movies
ax = movie_stats[movie_stats['#watch'] >= 1000].sort_values(by=['avg_rating'],ascending=False)[:10].plot(x='title',y='avg_rating',kind='bar',figsize=(12,6),legend=False,ylabel='avg-rating')
ax.bar_label(ax.containers[0])

# ratings are converted to binary since we will be working on ctr or like prediction
# 3 and below ratings are considered as dislike, 4 and 5 are considered as like
ratings_df.loc[ratings_df.rating <= 3,'rating'] = 0
ratings_df.loc[ratings_df.rating > 3,'rating'] = 1

ratings_df['rating'].value_counts()

# define label encoders for movies and users
user_encoder = preprocessing.LabelEncoder()
movie_encoder = preprocessing.LabelEncoder()

# make sure that all user and movie ids start from 1
ratings_df.user_id = user_encoder.fit_transform(ratings_df.user_id.values)
ratings_df.movie_id = movie_encoder.fit_transform(ratings_df.movie_id.values)

user_count = len(ratings_df['user_id'].unique())
movie_count = len(ratings_df['movie_id'].unique())

class CollaborativeFilteringModel(nn.Module):
    def __init__(self,n_users,n_movies,emb_dim=32):
        super().__init__()
        self.user_embeddings = nn.Embedding(n_users,emb_dim)
        self.movie_embeddings = nn.Embedding(n_movies,emb_dim)

        self.cosine_sim = nn.CosineSimilarity(dim=1, eps=1e-6)

    def forward(self,user,movie):
        user_emb = self.user_embeddings(user)
        movie_emb = self.movie_embeddings(movie)

        # apply cosine similarity to user-movie embeddings and scale it between 0-1
        # if user and movie embeddings are similar, that means higher chance to user to like the movie
        output = (self.cosine_sim(user_emb,movie_emb) + 1) / 2

        return output

model = CollaborativeFilteringModel(user_count,movie_count,emb_dim=64)
model.to(device)

def recommend_movies(user_id,top_k=10):
    # get all the movie_ids
    unique_movies = ratings_df.movie_id.unique()
    # get the movie_ids that are watched by the user
    watched_movies_by_user = ratings_df[ratings_df['user_id'] == user_id]['movie_id'].values
    # get the movie_ids that are not watched by the user
    not_watched_movies = torch.tensor(list(set(unique_movies) - set(watched_movies_by_user)))
    # create a tensor filled with user_id to fed the model
    user = torch.full((1,not_watched_movies.shape[0]),user_id)
    user = torch.squeeze(user)

    with torch.no_grad():
        # make the prediction
        user = user.to(device)
        not_watched_movies = not_watched_movies.to(device)
        movies = model(user,not_watched_movies)

    movies = torch.unsqueeze(movies,1)
    movies = torch.cat([torch.unsqueeze(not_watched_movies,1),movies],dim=1)
    # get the top k movies
    movies = movies[movies[:, 1].sort(descending=True)[1]]
    top_k_movies = movies[:top_k,:]
    movie_ids = top_k_movies[:,0].to(int).tolist()

    # create a recommendation dataframe
    recommended_movies = pd.DataFrame()
    for idx,m_id in enumerate(movie_ids):
        movie_row = ratings_df[ratings_df['movie_id']==m_id].iloc[0,:]
        title = movie_row.title
        genres = movie_row.genres

        recommended_movies.at[idx,'movie_id'] = m_id
        recommended_movies.at[idx,'score'] = top_k_movies[idx,1].item()
        recommended_movies.at[idx,'title'] = title
        recommended_movies.at[idx,'genres'] = genres

    return recommended_movies

top_k_movies = 5
user_id = random.randint(0,user_count+1)

print(f"Recommendations for user: {user_id}")
recommend_movies(user_id,top_k_movies)